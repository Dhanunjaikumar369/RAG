{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4658481a-f484-4d44-a742-52504306561a",
      "metadata": {
        "id": "4658481a-f484-4d44-a742-52504306561a"
      },
      "source": [
        "# Rag From Scratch: Indexing\n",
        "\n",
        "![Screenshot 2024-03-25 at 8.23.02 PM.png](indexing.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "095c203b",
      "metadata": {
        "id": "095c203b"
      },
      "source": [
        "## Set Environment Vars and API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "96d81ac8",
      "metadata": {
        "id": "96d81ac8"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'advanced-rag'\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQQ_API_KEY\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c574333e-6a0d-4f4e-8897-783cd71bdcc2",
      "metadata": {
        "id": "c574333e-6a0d-4f4e-8897-783cd71bdcc2"
      },
      "source": [
        "## Part 12: Multi-representation Indexing\n",
        "\n",
        "Flow:\n",
        "\n",
        " ![Screenshot 2024-03-16 at 5.54.55 PM.png](multiindexing.png)\n",
        "\n",
        "Docs:\n",
        "\n",
        "https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1bf368e7-ebf6-4469-bfa7-62466184afbb",
      "metadata": {
        "id": "1bf368e7-ebf6-4469-bfa7-62466184afbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://medium.com/@pankaj_pandey/introduction-to-retrieval-augmented-generation-rag-9209bf8a076d\")\n",
        "docs = loader.load()\n",
        "\n",
        "loader = WebBaseLoader(\"https://medium.com/humansdotai/an-introduction-to-ai-agents-e8c4afd2ee8f\")\n",
        "docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "431c9506-c6c0-463b-af77-9291a63f1d26",
      "metadata": {
        "id": "431c9506-c6c0-463b-af77-9291a63f1d26"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "chain = (\n",
        "    {\"doc\": lambda x: x.page_content}\n",
        "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
        "    | ChatGroq()\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "summaries = chain.batch(docs, {\"max_concurrency\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9fb1ce86",
      "metadata": {
        "id": "9fb1ce86",
        "outputId": "f41dff03-42a4-41d2-bb0f-8a28e440fb81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Retrieval-Augmented Generation (RAG) is an AI framework that enhances the accuracy and reliability of Large Language Models (LLMs) by grounding them in external knowledge bases. RAG addresses issues such as inconsistency and the lack of understanding of word meaning in LLMs by providing access to up-to-date facts and verifiable sources, thereby increasing user trust.\\n\\nRAG operates in two phases: retrieval and content generation. In the retrieval phase, relevant information is searched for and retrieved from external knowledge bases based on the user's prompt or question. In the content generation phase, the retrieved information is appended to the user's prompt and fed to the LLM, which synthesizes an answer based on both the augmented prompt and its internal representation of training data.\\n\\nThe benefits of RAG include accuracy and fact-checking, reduced bias and hallucination, and lower cost and maintenance. RAG finds applications in personalized responses, verifiable answers, and lowering computational and financial costs in enterprise settings.\\n\\nThe implementation of RAG involves a retrieval phase, where relevant information is gathered, and a generative phase, where the LLM synthesizes a response using both external and internal knowledge. RAG helps train LLMs to recognize limitations, such as ambiguous or complex queries, by prompting them to admit uncertainty or ask clarifying questions.\\n\\nWhile RAG is a powerful tool, there are ongoing challenges and innovations necessary to improve both the retrieval and generation ends of the process. Python code examples are provided to demonstrate the retrieval and generative phases in RAG.\",\n",
              " \"AI Agents are intelligent systems that can perform tasks, make decisions, and interact with their environment like humans do. They are powered by machine learning, natural language processing, and other advanced technologies, allowing them to learn from data, adapt to new information, and execute complex functions autonomously. AI Agents can take various forms, such as chatbots providing customer service or sophisticated robots used in healthcare and manufacturing. They are designed to understand and respond to human input, constantly evolving to enhance their capabilities.\\n\\nThese agents can navigate their environments and accomplish goals autonomously, addressing customer queries and making fast decisions based on real-time information. They simplify business processes and customer communications with an adaptive finesse. Unlike traditional AI interactions, AI agents operate independently, driven by goals rather than specific inputs. They are adept at browsing the internet, managing apps, conducting financial transactions, and controlling devices.\\n\\nAI Agents transform businesses by infusing tasks with enhanced performance and supercharged outcomes. They take on tasks that surpass human capabilities or liberate humans from mundane tasks. In business, AI Agents aren't just tools; they're game-changers, empowering enterprises to build new paths of efficiency, personalization, and cost-effectiveness.\\n\\nThe fundamental steps an AI Agent follows to fulfill a goal include:\\n\\n1. Understanding the objective\\n2. Formulating a task list\\n3. Gathering relevant information\\n4. Iterating and refining its strategy for more optimized progress\\n\\nAI Agents can revolutionize various business domains, such as finance, energy, transportation, healthcare, customer service, gaming, smart homes, robotics, natural language processing, cybersecurity, environmental monitoring, and social media.\\n\\nDifferent types of AI Agents include Simple Reflex Agents, Model-Based Reflex Agents, Goal-based Agents, Utility-Based AI Agents, Learning Agents, and Hierarchical AI Agents. Each type is tailored to address specific business challenges within their designated domains.\\n\\nAs AI advancement rapidly progresses, AI Agents promise increased autonomy, capable of making independent decisions with minimal human oversight. Their potential spans across diverse industries, and ethical considerations are crucial for responsible and beneficial utilization of these Agents. Market analysis suggests that 2024 is the year for enterprises to embrace the power of AI Agents.\"]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dc5614c1-121c-4ad5-8609-cc0e4a633ee9",
      "metadata": {
        "id": "dc5614c1-121c-4ad5-8609-cc0e4a633ee9"
      },
      "outputs": [],
      "source": [
        "from langchain.storage import InMemoryByteStore\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(collection_name=\"summaries\",\n",
        "                     embedding_function=hf_embeddings)\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryByteStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "# The retriever\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    byte_store=store,\n",
        "    id_key=id_key,\n",
        ")\n",
        "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
        "\n",
        "# Docs linked to summaries\n",
        "summary_docs = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(summaries)\n",
        "]\n",
        "\n",
        "# Add\n",
        "retriever.vectorstore.add_documents(summary_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "84b531f8",
      "metadata": {
        "id": "84b531f8",
        "outputId": "44fa141f-332b-41b4-aa74-af5c032bc204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['663d6817-1644-4bde-abc5-3d926a640362',\n",
              " 'c51c2beb-90eb-4096-91f8-cb72733866af']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8a849c72",
      "metadata": {
        "id": "8a849c72",
        "outputId": "d2e490e9-68a6-4dc3-c321-5380fe62abdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://medium.com/@pankaj_pandey/introduction-to-retrieval-augmented-generation-rag-9209bf8a076d', 'title': 'Introduction to Retrieval-Augmented Generation (RAG) | by Pankaj Pandey | Medium', 'description': 'The world is advancing rapidly, introducing new technologies and stacks in AI and other areas every day. Large Language Models (LLMs) are a significant innovation in this space. However, LLMs have…', 'language': 'en'}, page_content='Introduction to Retrieval-Augmented Generation (RAG) | by Pankaj Pandey | MediumOpen in appSign upSign inWriteSign upSign inMastodonIntroduction to Retrieval-Augmented Generation (RAG)Pankaj Pandey·Follow6 min read·Dec 16, 2023--ListenShareRAG systems aim to address the drawbacks of Large Language Models by incorporating factual information during response generation, mitigating issues such as knowledge cutoff and response hallucination.Retrieval Augmented Generation (RAG)The world is advancing rapidly, introducing new technologies and stacks in AI and other areas every day. Large Language Models (LLMs) are a significant innovation in this space. However, LLMs have drawbacks due to their knowledge cutoff and other reasons, leading to confident but inaccurate responses. The RAG systems aim to address this issue by incorporating factual information during response generation to prevent hallucination and retrieve accurate responses.Introduction:RAG is an AI framework that improves the accuracy and reliability of large language models (LLMs) by grounding them in external knowledge bases.LLMs can be inconsistent and prone to errors, lacking true understanding of word meaning.RAG addresses these issues by providing access to up-to-date facts and verifiable sources, increasing user trust.Purpose of RAG:Grounding LLMs on external knowledge for improved responses.Overcoming inconsistencies in LLM-generated answers.Challenges Addressed by RAG:Inconsistency in LLM responses.Lack of understanding of the meaning of words by LLMs.Reduction of opportunities for the model to leak sensitive data.Benefits of RAG:Accuracy and Fact-Checking:Ensures LLM responses are based on reliable sources, allowing users to verify claims.Reduced Bias and Hallucination:Limits LLM reliance on internal biases and prevents fabrication of information.Lower Cost and Maintenance:Reduces the need for continuous LLM retraining and updates, saving computational resources.How RAG Works:RAG consists of two distinct phases: retrieval and content generation. In the retrieval phase, algorithms search for and retrieve relevant information from external knowledge bases. This information is then used in the generative phase, where the LLM synthesizes an answer based on both the augmented prompt and its internal representation of training data.Phase 1: RetrievalRelevant information is retrieved from external sources based on the user\\'s prompt or question.Sources vary depending on the context (open-domain internet vs. closed-domain enterprise data).Phase 2: Content GenerationThe retrieved information is appended to the user\\'s prompt and fed to the LLM.The LLM generates a personalized answer based on the augmented prompt and its internal knowledge base.The answer can be delivered with links to its sources for transparency.Advantages and Applications of RAGRAG offers several advantages, including access to the latest, reliable facts, reduction in sensitive data leakage and decreased need for continuous model retraining. It finds applications in personalized responses, verifiable answers and lowering computational and financial costs in enterprise settings.Access to current and reliable information.Reduced opportunities for sensitive data leakage.Lower computational and financial costs in LLM-powered applications.Implementation and WorkflowsRAG operates in an “open book” manner, allowing LLMs to respond to questions by browsing through external content. It involves a retrieval phase, where relevant information is gathered and a generative phase, where the LLM synthesizes a response using both external and internal knowledge.Open-Book Approach:Contrasted with closed-book exams, where LLMs rely on memory.Model’s response involves browsing through external content.Workflow:Retrieval phase: Search and gather external information.Generative phase: Synthesize a personalized answer using internal and external knowledge.Teaching LLMs to Recognize LimitationsLLMs, when faced with ambiguous or complex queries, may provide inaccurate responses. RAG helps in training LLMs to recognize unanswerable questions and prompts them to either admit uncertainty or ask clarifying questions.Recognition of Limitations:LLMs prone to making things up in challenging scenarios.Training LLMs to explicitly recognize unanswerable questions.Challenges and Ongoing Innovations in Retrieval-Augmented GenerationWhile RAG is a powerful tool, there are still some challenges persist and ongoing innovations are necessary. Lots of Research is focused on improving both the retrieval and generation ends of the process to enhance the effectiveness of RAG.Challenges:Imperfections in RAG.Enriching prompts with relevant information using vectors.Innovations and Research:Focus on retrieval: Finding and fetching the most relevant information.Focus on generation: Structuring information for richer responses.Example Scenario: Customer Care ChatbotAlice, an employee, asks about taking vacation in half-day increments.The LLM retrieves relevant data from Alice\\'s HR files and company policies.It generates a personalized answer confirming her vacation allowance and half-day eligibility.The answer is delivered with links to the HR files and policies for verification.Challenges and Future DirectionsTraining LLMs to recognize \"unknowns\" and avoid making things up.Improving retrieval algorithms for finding the most relevant information.Optimizing generation techniques for incorporating retrieved information effectively.Python Code Examples:1. Simple Retrieval with Elasticsearch:from elasticsearch import Elasticsearches = Elasticsearch()query = \"early dismissal school Wednesdays\"results = es.search(index=\"documents\", query={\"query\": {\"match\": {\"text\": query}}})# Process results and use them to augment the LLM prompt...2. Combining Retrieval and Generation with Transformers:# Using a transformer-based model with RAG for information retrieval and generationfrom transformers import pipelinerag_qa_pipeline = pipeline(\"question-answering\", model=\"facebook/rag-token-base\", retriever=\"facebook/rag-token-base\")question = \"What is retrieval-augmented generation?\"answer = rag_qa_pipeline(question, truncation=True, return_prompt=True)print(answer)from transformers import AutoTokenizer, AutoModelForSequenceClassificationtokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")model = AutoModelForSequenceClassification.from_pretrained(\"rag/bert-base-uncased-rag\")prompt = \"Alice asks about taking vacation in half-day increments.\"retrieved_info = ...  # Retrieved information from external sourceencoded_prompt = tokenizer(prompt + retrieved_info, return_tensors=\"pt\")output = model(**encoded_prompt)# Process output and use it to generate the LLM response...# Sample Python code demonstrating the retrieval phase in RAGdef retrieval_phase(user_prompt, external_data):    # Algorithm to search and retrieve relevant information    retrieved_info = search_and_retrieve(user_prompt, external_data)    return retrieved_info# Sample Python code demonstrating the generative phase in RAGdef generative_phase(augmented_prompt, internal_data):    # Algorithm to synthesize a personalized answer using internal and external knowledge    answer = generate_response(augmented_prompt, internal_data)    return answer3. RAG Example in a question answering system:# Example of using RAG in a question answering systemfrom transformers import RagTokenizer, RagRetriever, RagSequenceForGenerationtokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")retriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# Retrieve relevant informationinput_text = \"What is retrieval-augmented generation?\"retrieved_info = retriever.retrieve(input_text)# Generate response using RAGgenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))4. Personalized and Verifiable Responses with RAGRetrieval-augmented generation (RAG) enables large language models (LLMs) to provide personalized responses without constant retraining. It reduces the need for manual scripting in chatbots, allowing the model to adapt to new information dynamically.# Using RAG to generate personalized responses in a chatbotfrom transformers import RagRetriever, RagSequenceForGenerationretriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# User\\'s queryuser_query = \"Can I take vacation in half-day increments?\"# Retrieve relevant informationretrieved_info = retriever.retrieve(user_query)# Generate personalized response using RAGgenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))5. Teaching the Model to Recognize UnknownsLLMs need explicit training to recognize and admit when they cannot answer certain questions. RAG addresses the challenge of ambiguous queries, complex questions and situations where the model lacks information.# Training an LLM to recognize unknown questions using RAGfrom transformers import RagRetriever, RagSequenceForGenerationretriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# User\\'s ambiguous queryambiguous_query = \"How much vacation time do I have?\"# Retrieve relevant informationretrieved_info = retriever.retrieve(ambiguous_query)# Train the model to recognize unknowns# ...# Generate response using RAG, considering the unknown recognitiongenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))Note: These are simplified examples to understand the basic concepts, the actual implementation may require more complex code and libraries depending on the specific use case and desired functionalities.Conclusion:RAG is a promising approach for improving LLM accuracy and reliability, offering benefits like factual grounding, reduced bias and lower maintenance costs. While challenges remain in areas like unknown recognition and retrieval optimization, ongoing research is pushing the boundaries of RAG capabilities and paving the way for more trustworthy and informative LLM applications.Supporting Information:Vector databases play a crucial role in RAG by efficiently indexing, storing and retrieving information.Lots of Research emphasizes the imperfections of RAG and the need for ongoing improvements in its implementation.Remember: This is a preliminary analysis. Further research and validation are needed to ensure the accuracy and completeness of the information presented.SourcesData-Science-Pipeline-DetectorRetrieval-augmented-generation-RAGLarge Language ModelsRagMachine LearningData ScienceAI----FollowWritten by Pankaj Pandey283 FollowersExpert in software technologies with proficiency in multiple languages, experienced in Generative AI, NLP, Bigdata, and application development.FollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              " Document(metadata={'source': 'https://medium.com/humansdotai/an-introduction-to-ai-agents-e8c4afd2ee8f', 'title': 'An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | Medium', 'description': 'Artificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make…', 'language': 'en'}, page_content='An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | MediumOpen in appSign upSign inWriteSign upSign inAn Introduction to AI AgentsHumans.ai·FollowPublished inhumansdotai·7 min read·Dec 27, 2023--1ListenShareArtificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make decisions, and interact with their environment just like humans do. Powered by machine learning, natural language processing, and other cutting-edge technologies, AI Agents can learn from data, adapt to new information, and execute complex functions autonomously. They exist in various forms, from chatbots providing customer service to sophisticated robots created for healthcare and manufacturing. AI Agents are designed to understand, analyze, and respond to human input, constantly evolving to enhance their capabilities.In this article, we’ll delve into the world of AI agents, exploring their functionalities, the technology behind their intelligence, their applications across industries, and the ethical considerations that arise as these agents become increasingly integrated into our daily lives.Join us on an amazing journey through the fascinating world of AI agents and their transformative potential!Understanding AI AgentsAI Agents navigate their environments and accomplish goals autonomously, free from human intervention. These savvy programs address customer queries, and make fast decisions based on real-time information, revolutionizing the landscape of customer engagement. Think of them as the pioneers redefining our interactions — they’re simplifying business processes and customer communications with an adaptive finesse that transforms the ordinary into extraordinary.These agents work their magic by perceiving their surroundings and executing actions through a spectrum of tools — from rule-based systems and decision-makers to the benefits of machine learning. As digital decision-makers fueled by past and present inputs, AI Agents pursue optimal outcomes, slowly carving the path to a smarter and more intuitive future.AI Agents are revolutionizing the way we interact with technology. Unlike traditional AI interactions where prompts are necessary for responses, AI agents operate independently, driven by goals rather than specific inputs. They’re autonomous problem solvers, seamlessly adapting to new information and environments, evolving with every task to achieve their objectives optimally.In contrast to standard automation processes rooted in fixed parameters and training data, AI Agents flourish in uncertain landscapes, navigating uncharted territories and handling vast streams of fresh data. They’re the new face of intelligent automation. But AI Agents aren’t just intelligent; they’re adept at using computers. From browsing the internet and managing apps to conducting financial transactions and controlling devices, their capabilities are vast and versatile.More importantly, the emergence of AI Agents signifies a step towards Artificial General Intelligence (AGI), where machines will emulate human-like flexibility and unparalleled proficiency across diverse domains. AI Agents represent a groundbreaking step toward this future, where technology’s potential is unknown.How does an AI Agent work?AI Agents operate similarly to popular AI solutions present on the market, namely they require users to input an objective, after which the AI Agent initiates its journey toward the goal by engaging with the core Language Learning Models that operate in the background to return its first output and showcase its understanding of the task at hand.Next comes the meticulous crafting of a task list. Driven by the defined goal, the AI Agent formulates a sequence of tasks, prioritizing their order of completion. Once satisfied with its plan, it delves into information retrieval.Functioning like an experimented computer user, the Agent navigates the vast domain of the internet to gather relevant information. Some advanced agents collaborate with other AI models, enabling access to specialized tasks like image generation and computer vision functionalities. All the collected data is meticulously managed by the Agent and used to relay information back to the user and refine its strategy for more optimized progress.As each task is completed, the Agent actively seeks feedback, both from external sources and through its internal thought process, to estimate its distance from the ultimate goal. Until its objective is achieved, the agent relentlessly iterates, crafting new tasks and seeking more data and feedback to advance toward its goal.These are the fundamental steps a typical AI Agent follows to fulfill any given goal. Yet, the sequencing of steps may vary depending on the different configurations or objectives the AI agent was designed for.How AI Agents transform businessesAI Agents stand as catalysts, elevating the game for businesses by infusing tasks with heightened performance and supercharged outcomes. These agents take on tasks that either surpass human capabilities or liberate us from those tasks we’d rather not tackle. In business, AI Agents aren’t just tools; they’re game-changers, empowering enterprises to rise beyond limits and build new paths of efficiency, personalization, and cost-effectiveness. Overall, AI Agents serve as guardians against errors, the solvers of intricate puzzles, and the creators of new fields of opportunities.AI Agents Characteristics:✅ Enhanced Efficiency: AI Agents perform tasks with impeccable speed and accuracy, effortlessly surpassing humans. They’re the masters of repetitive tasks, allowing humans to focus their attention on complex problem-solving.✅ Tailored Personalization: AI Agents use data analytics to curate personalized customer solutions and recommendations.✅ Unmatched Scalability: Virtual agents boast adaptability like no other, effortlessly scaling their operations to meet the surge during peak seasons or unexpected demand spikes, empowering businesses with unparalleled flexibility.✅ Always On: These tireless digital agents operate around the clock, offering 24/7 customer service. No overtime, no weekend shifts, just unwavering availability.✅ Reduced Costs: By automating routine tasks, AI Agents are the tool that slashes labor costs for businesses. Moreover, they’re handling numerous customer inquiries simultaneously, reducing the need for additional staff.How AI Agents are revolutionizing the economyAI Agents have become indispensable across various business domains, revolutionizing service delivery, supply chains, and marketing strategies. These multifaceted AI Agents can become the backbone of modern business operations, shaping the future with their unparalleled versatility and transformative capabilities, serving as catalysts for transformative change, with examples transcending multiple industries:• Finance: Autonomous agents redefine trading, risk management, and fraud detection. Hedge funds leverage AI-powered agents to analyze market data and execute trades intelligently.• Energy: In power grids and energy markets, adaptive agents streamline operations, automating power generation and distribution with precision and efficiency.• Transportation: Automobile companies like Tesla utilize AI-based agents to develop self-driving cars. These autonomous agents make decisions based on sensory inputs, optimizing traffic flow and supply chain logistics. AI Agents can also help manage traffic flow and improve logistics and supply chain management.• Healthcare: Autonomous agents revolutionize diagnosis and treatment by analyzing medical records, crafting personalized treatment plans, and optimizing resource allocation.• Customer Service: Virtual assistants and AI-driven chatbots enhance customer service across diverse industries, ensuring seamless interactions.• Gaming: Intelligent agents enrich gaming experiences by creating challenging opponents in simulations, enhancing realism for players.• Smart Homes and Buildings: Agents optimize energy consumption and improve comfort by controlling heating, lighting, and other systems in smart homes and buildings.• Robotics: AI Agents can control robots and automate tasks, driving operational efficiency.• Natural Language Processing: Agents facilitate language translation, question answering, and chatbot communication, bridging gaps in user interactions.• Cybersecurity: AI Agents can bolster security measures by detecting intrusions, analyzing malware, and fortifying network security.• Environmental Monitoring: AI Agents contribute to sustainability efforts by monitoring natural resources, tracking climate changes, and enhancing environmental conservation.• Social Media: Agents analyze social media data, unveiling trends, patterns, and personalized recommendations, enriching user experiences.Categories of AI AgentsAI Agents operate nearly independently, navigating their surroundings, interpreting information, and making decisions based on keen observations. Different types of AI Agents are tailor-made to address specific business challenges within their designated domains.Classifying AI Agents involves discerning the impact of their actions on their perceived intelligence and capacities. By delving into the distinct traits of each agent category, there’s ample potential to elevate their efficiency and yield superior outcomes.Simple Reflex AgentsA simple reflex agent operates within predefined guidelines, reacting solely to immediate circumstances. It’s most effective in stable environments with straightforward actions, where its reactive nature suits the situation. Simple Reflex agents work based on condition-action rules, determining responses based on specific conditions.Model-Based Reflex AgentsA model-based Reflex Agent operates on a current percept and an internal state representing the hidden aspects of the world. It adapts its internal state based on how the world evolves and the impact of its actions on it. Model-based Reflex Agents work based on condition-action rules, which specify the appropriate action to take in a particular situation. Unlike simple reflex agents, they also factor in their internal state during decision-making.Goal-based AgentsGoal-based Agents leverage information from their surroundings to achieve defined objectives. Employing search algorithms, these agents efficiently navigate through their environments to reach their set goals.Also known as rule-based, they follow predefined directives to accomplish tasks and act based on specific conditions. They excel in handling complex tasks, finding their utility in robotics, computer vision, and natural language processing. Unlike their basic counterparts, goal-based agents identify optimal decision-making paths tailored to their desired outcomes or goals.Utility-Based AI AgentsUtility-based Agents aim to maximize utility functions or values. They cherry-pick actions with the highest expected utility, measuring how favorable the outcome is. Due to this design, utility-based Agents excel in navigating complex and uncertain scenarios, adapting flexibly to situations.Learning AgentsAI Learning Agents constantly enhance performance through the power of learning. These software agents start with basic knowledge and refine themselves through machine learning, constantly evolving to achieve better outcomes. AI learning agents observe, learn, and act based on feedback loops, constantly adapting to shape their behavior for future interactions.Hierarchical AI AgentsHierarchical Agents are organized in tiers, with higher-level agents orchestrating lower-level counterparts. These levels, tailored to the system’s complexity, excel in diverse fields like robotics, manufacturing, and transportation, adept at coordinating multiple tasks and sub-tasks seamlessly.ConclusionIn a generation characterized by rapid AI advancement, the trajectory of AI Agents promises unparalleled autonomy, capable of making independent decisions with minimal human oversight. Their potential spans across diverse industries, revolutionizing customer service, predicting market demands, optimizing production lines, and beyond.The extensive applications of AI Agents hint at vast promise, yet ethical considerations remain most important. Responsible and beneficial utilization of these Agents is essential for enterprises venturing into this transformative journey.Market analysis shows that the 2024 year it’s the moment to embrace the formidable power of AI Agents at the enterprise’s level.AIArtificial IntelligenceAi AgentAGITech----1FollowWritten by Humans.ai393 Followers·Editor for humansdotaiHeart driven AIFollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.docstore.mget(doc_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f111ca83-3e56-4785-bac3-99948cd8df1b",
      "metadata": {
        "id": "f111ca83-3e56-4785-bac3-99948cd8df1b",
        "outputId": "6be2a2a7-6285-424b-93f9-9694879ec2ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'doc_id': 'c51c2beb-90eb-4096-91f8-cb72733866af'}, page_content=\"AI Agents are intelligent systems that can perform tasks, make decisions, and interact with their environment like humans do. They are powered by machine learning, natural language processing, and other advanced technologies, allowing them to learn from data, adapt to new information, and execute complex functions autonomously. AI Agents can take various forms, such as chatbots providing customer service or sophisticated robots used in healthcare and manufacturing. They are designed to understand and respond to human input, constantly evolving to enhance their capabilities.\\n\\nThese agents can navigate their environments and accomplish goals autonomously, addressing customer queries and making fast decisions based on real-time information. They simplify business processes and customer communications with an adaptive finesse. Unlike traditional AI interactions, AI agents operate independently, driven by goals rather than specific inputs. They are adept at browsing the internet, managing apps, conducting financial transactions, and controlling devices.\\n\\nAI Agents transform businesses by infusing tasks with enhanced performance and supercharged outcomes. They take on tasks that surpass human capabilities or liberate humans from mundane tasks. In business, AI Agents aren't just tools; they're game-changers, empowering enterprises to build new paths of efficiency, personalization, and cost-effectiveness.\\n\\nThe fundamental steps an AI Agent follows to fulfill a goal include:\\n\\n1. Understanding the objective\\n2. Formulating a task list\\n3. Gathering relevant information\\n4. Iterating and refining its strategy for more optimized progress\\n\\nAI Agents can revolutionize various business domains, such as finance, energy, transportation, healthcare, customer service, gaming, smart homes, robotics, natural language processing, cybersecurity, environmental monitoring, and social media.\\n\\nDifferent types of AI Agents include Simple Reflex Agents, Model-Based Reflex Agents, Goal-based Agents, Utility-Based AI Agents, Learning Agents, and Hierarchical AI Agents. Each type is tailored to address specific business challenges within their designated domains.\\n\\nAs AI advancement rapidly progresses, AI Agents promise increased autonomy, capable of making independent decisions with minimal human oversight. Their potential spans across diverse industries, and ethical considerations are crucial for responsible and beneficial utilization of these Agents. Market analysis suggests that 2024 is the year for enterprises to embrace the power of AI Agents.\")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What is agent\"\n",
        "sub_docs = vectorstore.similarity_search(query,k=1)\n",
        "sub_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "729074f9-8bde-4c76-a7da-4cc0e50ed52d",
      "metadata": {
        "id": "729074f9-8bde-4c76-a7da-4cc0e50ed52d",
        "outputId": "550c951d-de4b-4977-9480-7f6476b9015a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/dhanunjaikumar/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | MediumOpen in appSign upSign inWriteSign upSign inAn Introduction to AI AgentsHumans.ai·FollowPublished inhumansdotai·7 min read·Dec 27, 2023--1ListenShareArtificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make decisions, and interact with their environme'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs = retriever.get_relevant_documents(query,n_results=1)\n",
        "retrieved_docs[0].page_content[0:500]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d09151ce-aea1-4574-84ab-a72f17bf59b4",
      "metadata": {
        "id": "d09151ce-aea1-4574-84ab-a72f17bf59b4"
      },
      "source": [
        "## Part 13: ColBERT\n",
        "\n",
        "RAGatouille makes it as simple to use ColBERT.\n",
        "\n",
        "ColBERT generates a contextually influenced vector for each token in the passages.\n",
        "\n",
        "ColBERT similarly generates vectors for each token in the query.\n",
        "\n",
        "Then, the score of each document is the sum of the maximum similarity of each query embedding to any of the document embeddings:\n",
        "\n",
        "See [here](https://hackernoon.com/how-colbert-helps-developers-overcome-the-limits-of-rag) and [here](https://python.langchain.com/docs/integrations/retrievers/ragatouille) and [here](https://til.simonwillison.net/llms/colbert-ragatouille)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "TxcmPHugWRY5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxcmPHugWRY5",
        "outputId": "e338f6d0-178a-412c-f5f7-ae2397d65179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ragatouille\n",
            "  Downloading ragatouille-0.0.8.post2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting colbert-ai==0.2.19 (from ragatouille)\n",
            "  Downloading colbert-ai-0.2.19.tar.gz (86 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in ./.venv/lib/python3.10/site-packages (from ragatouille) (1.7.4)\n",
            "Collecting fast-pytorch-kmeans==0.2.0.1 (from ragatouille)\n",
            "  Downloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.0 (from ragatouille)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain_core<0.2.0,>=0.1.4 (from ragatouille)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting llama-index>=0.7 (from ragatouille)\n",
            "  Downloading llama_index-0.10.59-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting onnx<2.0.0,>=1.15.0 (from ragatouille)\n",
            "  Downloading onnx-1.16.2-cp310-cp310-macosx_11_0_universal2.whl.metadata (16 kB)\n",
            "Collecting sentence-transformers<3.0.0,>=2.2.2 (from ragatouille)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting srsly==2.4.8 (from ragatouille)\n",
            "  Downloading srsly-2.4.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=1.13 in ./.venv/lib/python3.10/site-packages (from ragatouille) (2.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.36.2 in ./.venv/lib/python3.10/site-packages (from ragatouille) (4.43.4)\n",
            "Collecting voyager<3.0.0,>=2.0.2 (from ragatouille)\n",
            "  Downloading voyager-2.0.9-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
            "Collecting bitarray (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (34 kB)\n",
            "Collecting datasets (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting flask (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting git-python (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
            "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.0.1)\n",
            "Collecting ninja (from colbert-ai==0.2.19->ragatouille)\n",
            "  Using cached ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.14.0)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (4.66.5)\n",
            "Collecting ujson (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from fast-pytorch-kmeans==0.2.0.1->ragatouille) (1.26.4)\n",
            "Collecting pynvml (from fast-pytorch-kmeans==0.2.0.1->ragatouille)\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.3 (from srsly==2.4.8->ragatouille)\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.6.7)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.1.93)\n",
            "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.10/site-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (1.33)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain_core<0.2.0,>=0.1.4->ragatouille)\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core==0.10.59 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_core-0.10.59-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index>=0.7->ragatouille)\n",
            "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_readers_file-0.1.32-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (2024.6.1)\n",
            "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (3.3)\n",
            "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.39.0)\n",
            "Collecting pandas (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (10.4.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (0.9.0)\n",
            "Collecting wrapt (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in ./.venv/lib/python3.10/site-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (4.25.4)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.5.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.24.5)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (3.15.4)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (2024.7.24)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->ragatouille) (3.21.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core<0.2.0,>=0.1.4->ragatouille) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->ragatouille) (3.10.6)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_cloud-0.0.11-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./.venv/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (2024.7.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
            "Collecting pyarrow-hotfix (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2023.5.0 (from llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting Werkzeug>=3.0.0 (from flask->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting itsdangerous>=2.1.2 (from flask->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting click>=8.1.3 (from flask->colbert-ai==0.2.19->ragatouille)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting blinker>=1.6.2 (from flask->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.13->ragatouille) (2.1.5)\n",
            "Collecting gitpython (from git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.13->ragatouille) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille) (2.5)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.0.5)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.9.0)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.0.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->llama-index-core==0.10.59->llama-index>=0.7->ragatouille)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.59->llama-index>=0.7->ragatouille) (1.16.0)\n",
            "Downloading ragatouille-0.0.8.post2-py3-none-any.whl (41 kB)\n",
            "Downloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl (8.8 kB)\n",
            "Downloading srsly-2.4.8-cp310-cp310-macosx_11_0_arm64.whl (491 kB)\n",
            "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "Downloading llama_index-0.10.59-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_core-0.10.59-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.2-cp310-cp310-macosx_11_0_universal2.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "Downloading voyager-2.0.9-cp310-cp310-macosx_11_0_arm64.whl (356 kB)\n",
            "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
            "Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
            "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.32-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Downloading bitarray-2.9.2-cp310-cp310-macosx_11_0_arm64.whl (124 kB)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Using cached ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (270 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "Downloading ujson-5.10.0-cp310-cp310-macosx_11_0_arm64.whl (51 kB)\n",
            "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
            "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading llama_cloud-0.0.11-py3-none-any.whl (154 kB)\n",
            "Downloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-macosx_11_0_arm64.whl (27.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
            "Downloading wrapt-1.16.0-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.4.1-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Downloading greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl (270 kB)\n",
            "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: colbert-ai\n",
            "  Building wheel for colbert-ai (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114762 sha256=9dbebf86fb0a610a9c5905a656cade3fe4d73bdbbea3fb6729942a2f4c8c3d63\n",
            "  Stored in directory: /Users/dhanunjaikumar/Library/Caches/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\n",
            "Successfully built colbert-ai\n",
            "Installing collected packages: striprtf, pytz, ninja, dirtyjson, bitarray, xxhash, wrapt, Werkzeug, voyager, ujson, tzdata, smmap, pypdf, pynvml, pyarrow-hotfix, pyarrow, packaging, onnx, itsdangerous, greenlet, fsspec, dill, click, catalogue, blinker, srsly, pandas, nltk, multiprocess, gitdb, flask, deprecated, llama-cloud, gitpython, fast-pytorch-kmeans, llama-index-legacy, llama-index-core, langchain_core, git-python, datasets, sentence-transformers, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, langchain-community, colbert-ai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, llama-index-program-openai, llama-index-question-gen-openai, llama-index, ragatouille\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.2.28\n",
            "    Uninstalling langchain-core-0.2.28:\n",
            "      Successfully uninstalled langchain-core-0.2.28\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.0.1\n",
            "    Uninstalling sentence-transformers-3.0.1:\n",
            "      Successfully uninstalled sentence-transformers-3.0.1\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.2.2\n",
            "    Uninstalling langchain-text-splitters-0.2.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.2.2\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.2.11\n",
            "    Uninstalling langchain-community-0.2.11:\n",
            "      Successfully uninstalled langchain-community-0.2.11\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.2.12\n",
            "    Uninstalling langchain-0.2.12:\n",
            "      Successfully uninstalled langchain-0.2.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 1.0.8 requires langchain-core<0.3,>=0.2.17, but you have langchain-core 0.1.52 which is incompatible.\n",
            "langchain-groq 0.1.9 requires langchain-core<0.3.0,>=0.2.26, but you have langchain-core 0.1.52 which is incompatible.\n",
            "langchain-openai 0.1.20 requires langchain-core<0.3.0,>=0.2.26, but you have langchain-core 0.1.52 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Werkzeug-3.0.3 bitarray-2.9.2 blinker-1.8.2 catalogue-2.0.10 click-8.1.7 colbert-ai-0.2.19 datasets-2.20.0 deprecated-1.2.14 dill-0.3.8 dirtyjson-1.0.8 fast-pytorch-kmeans-0.2.0.1 flask-3.0.3 fsspec-2024.5.0 git-python-1.0.3 gitdb-4.0.11 gitpython-3.1.43 greenlet-3.0.3 itsdangerous-2.2.0 langchain-0.1.20 langchain-community-0.0.38 langchain-text-splitters-0.0.2 langchain_core-0.1.52 llama-cloud-0.0.11 llama-index-0.10.59 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.59 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.27 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.32 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 multiprocess-0.70.16 ninja-1.11.1.1 nltk-3.8.1 onnx-1.16.2 packaging-23.2 pandas-2.2.2 pyarrow-17.0.0 pyarrow-hotfix-0.6 pynvml-11.5.3 pypdf-4.3.1 pytz-2024.1 ragatouille-0.0.8.post2 sentence-transformers-2.7.0 smmap-5.0.1 srsly-2.4.8 striprtf-0.0.26 tzdata-2024.1 ujson-5.10.0 voyager-2.0.9 wrapt-1.16.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install ragatouille"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "96deaaa9-5101-48a5-a93d-b8af0122430f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "f55f34da36fb4016a4a0494086c64641",
            "0b1d585d85824f888d39522ecb8a6f1f",
            "5c3f767339684ba894d39282b9edbbb7",
            "fad322935e6b4fbc8276abc2b85e1836",
            "4be9692e8be043c489f06a3abf27c64d",
            "4ba71b0eaff04537bc50bbca33aa4630",
            "7ac87a6e34984140a02a704c3e4ccf48",
            "1e9de6e09f82454381a7becdec58e8bf",
            "f347b06929df4fab84b1ab26338f4af6",
            "033667bb55444c3f9f629dd9ede1ec99",
            "d1773c06eeee4678953761276e51dcf1",
            "22cf57b760304a978df66d62eed18444",
            "ce12ae54e3424ac8835ab37b5d2538a4",
            "6c9de4615d71479ba94ee6c71de73ccb",
            "232ef42c0b9242a993254f861575d96f",
            "4606c9d425314c089779736ccd5e2450",
            "a6116981916849eebf946d98ae8691e0",
            "779f2ee7130e4d44b213dab4098672e2",
            "6b363d6326ea427389d849068c012232",
            "91d690a1ba354771bb838a2b0b18b79e",
            "5dd7c87d28b149cb940316e1349fee7e",
            "3978e89d4c3e4d79b2878d24cb9b9c04",
            "8f75d8d2a1ab4abc8b96fadf5f600dfb",
            "59123ebb89ad4cbdb1e720883ecda233",
            "20d54451d0174a8bb63aceef38882400",
            "4aec2d6583fb43e28748dac7ab2baab0",
            "ed62cedbc6024c61b76131f992e31af2",
            "ac6a1048895c4491ad1e68ae54e8f8e9",
            "5498b24697224a8eb9a4ecfde6ac4846",
            "841c4cb47e564e0ebb8095778d66c009",
            "252fa7545c1743f39d91cac5f3bfd98f",
            "f864969ec82b4317ba1e703c1c8d22c1",
            "c33ad59265ab41aba4c0e1cd7ee3070c",
            "6c255f2548db49dcae4895a12932ce00",
            "9844837561f6449485a618a5ddefabdc",
            "8661582dd02949ab9d922551b764c7b9",
            "ac4a22ba42da4369acd7a615f7e0b863",
            "d22750241cf04e32a11e7bc3a68cc2f4",
            "1b26567be0e547bf9653330ee3e9657a",
            "9dd945ef26ff46a481966617b067213b",
            "1c1157f83feb4b6cad7ef629a67f8e47",
            "9e56ab04c7b54dba911e615c64c8e8c8",
            "8bc753efac9445ddad71fca8a8ed3ae5",
            "8371a09564324bf5ade74da741e1afc6",
            "cc321c998b874fb79b1aedcdbf8eb532",
            "ee1cace3748c49999acec51380c87808",
            "ba5f73bc04a04df1bec10ec485127439",
            "faaa3db108f54b2b8cc68d26f814cb87",
            "4f08bd4dab974813aa757ec9c4aa963a",
            "a7e8f141bc434de6826b9d288710ae71",
            "cbcadf9a603b48acb63dae5b8ae018e3",
            "b75a53aa019d4fb3a1dd49fae3b71028",
            "b5e438a896a44bc58a805ccc5ab03dc4",
            "b9463b08a33e4bdeaa2f13f307c94a4e",
            "8d73beaf48cf49d39b0e0282883443a3",
            "1a13075d97244a8dad0d45bf48378d91",
            "088c9c3f25f7404cb36c641a85026683",
            "c793d1c900904cca8ffedf8aff00d9bc",
            "8623a516b70244efb6d672cd81b142a8",
            "37314ac1be75491fbcb9b1545dc3badc",
            "51cad1a6c9134a1c9b818222ac7138e7",
            "61af1a241ae54cf5ab71425047c34d3d",
            "a924f492ca3f4a5fbd48c57aee80c767",
            "119d9d2a3ae64961a46254e7a0a96e82",
            "c8dcb6be89934c408501870533049506",
            "605810870a4040deb1cd10ab0a057d5a",
            "a711db6e16974e498d689038a66344de",
            "da31decacd0a49fd8804be39dfab86f3",
            "3d3699228def403bbee1a5831c0ef5ca",
            "139fc4cf87d6413b852799dd74e9bab4",
            "46b90df0d418488f90c8543486a98e9e",
            "796ec3b798154839bfba5d5f26ba0eb2",
            "2c02a1c5ce2e44efbe2052dcc585b8ab",
            "ccf0334b4758450892167661416980ab",
            "6468201ba1814586a23be3ed3f78f190",
            "c16840916a2f45f1a11511542aff5b90",
            "b5f3df4f63c84fcf9222e95d5380a899"
          ]
        },
        "id": "96deaaa9-5101-48a5-a93d-b8af0122430f",
        "outputId": "bf1e8d2c-64cf-4918-d452-1f92fff705f3"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Plain typing.TypeAlias is not valid as type argument",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/ragatouille/data/preprocessors.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m \u001b[39mimport\u001b[39;00m Document\n\u001b[1;32m      3\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceSplitter\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Document' from 'llama_index' (unknown location)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragatouille\u001b[39;00m \u001b[39mimport\u001b[39;00m RAGPretrainedModel\n\u001b[1;32m      2\u001b[0m RAG \u001b[39m=\u001b[39m RAGPretrainedModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mcolbert-ir/colbertv2.0\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/ragatouille/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.0.8post2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mRAGPretrainedModel\u001b[39;00m \u001b[39mimport\u001b[39;00m RAGPretrainedModel\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mRAGTrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m RAGTrainer\n\u001b[1;32m      5\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mRAGPretrainedModel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRAGTrainer\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/ragatouille/RAGPretrainedModel.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_compressors\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseDocumentCompressor\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseRetriever\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragatouille\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus_processor\u001b[39;00m \u001b[39mimport\u001b[39;00m CorpusProcessor\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragatouille\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessors\u001b[39;00m \u001b[39mimport\u001b[39;00m llama_index_sentence_splitter\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragatouille\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mintegrations\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     RAGatouilleLangChainCompressor,\n\u001b[1;32m     12\u001b[0m     RAGatouilleLangChainRetriever,\n\u001b[1;32m     13\u001b[0m )\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/ragatouille/data/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcorpus_processor\u001b[39;00m \u001b[39mimport\u001b[39;00m CorpusProcessor\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpreprocessors\u001b[39;00m \u001b[39mimport\u001b[39;00m llama_index_sentence_splitter\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_data_processor\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainingDataProcessor\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/ragatouille/data/corpus_processor.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39muuid\u001b[39;00m \u001b[39mimport\u001b[39;00m uuid4\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragatouille\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessors\u001b[39;00m \u001b[39mimport\u001b[39;00m llama_index_sentence_splitter\n\u001b[1;32m      7\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCorpusProcessor\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m      9\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m         document_splitter_fn: Optional[Callable] \u001b[39m=\u001b[39m llama_index_sentence_splitter,\n\u001b[1;32m     11\u001b[0m         preprocessing_fn: Optional[Union[Callable, \u001b[39mlist\u001b[39m[Callable]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     ):\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/ragatouille/data/preprocessors.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceSplitter\n\u001b[1;32m      4\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Document\n\u001b[1;32m      6\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceSplitter\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mllama_index_sentence_splitter\u001b[39m(\n\u001b[1;32m     10\u001b[0m     documents: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m], document_ids: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m], chunk_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[1;32m     11\u001b[0m ):\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/__init__.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmock_embed_model\u001b[39;00m \u001b[39mimport\u001b[39;00m MockEmbedding\n\u001b[1;32m     17\u001b[0m \u001b[39m# indices\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# loading\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     ComposableGraph,\n\u001b[1;32m     21\u001b[0m     DocumentSummaryIndex,\n\u001b[1;32m     22\u001b[0m     GPTDocumentSummaryIndex,\n\u001b[1;32m     23\u001b[0m     GPTKeywordTableIndex,\n\u001b[1;32m     24\u001b[0m     GPTListIndex,\n\u001b[1;32m     25\u001b[0m     GPTRAKEKeywordTableIndex,\n\u001b[1;32m     26\u001b[0m     GPTSimpleKeywordTableIndex,\n\u001b[1;32m     27\u001b[0m     GPTTreeIndex,\n\u001b[1;32m     28\u001b[0m     GPTVectorStoreIndex,\n\u001b[1;32m     29\u001b[0m     KeywordTableIndex,\n\u001b[1;32m     30\u001b[0m     KnowledgeGraphIndex,\n\u001b[1;32m     31\u001b[0m     PropertyGraphIndex,\n\u001b[1;32m     32\u001b[0m     ListIndex,\n\u001b[1;32m     33\u001b[0m     RAKEKeywordTableIndex,\n\u001b[1;32m     34\u001b[0m     SimpleKeywordTableIndex,\n\u001b[1;32m     35\u001b[0m     SummaryIndex,\n\u001b[1;32m     36\u001b[0m     TreeIndex,\n\u001b[1;32m     37\u001b[0m     VectorStoreIndex,\n\u001b[1;32m     38\u001b[0m     load_graph_from_storage,\n\u001b[1;32m     39\u001b[0m     load_index_from_storage,\n\u001b[1;32m     40\u001b[0m     load_indices_from_storage,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[39m# structured\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstruct_store\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     SQLDocumentContextBuilder,\n\u001b[1;32m     46\u001b[0m )\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/__init__.py:32\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlist\u001b[39;00m \u001b[39mimport\u001b[39;00m GPTListIndex, ListIndex, SummaryIndex\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlist\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     GPTListIndex,\n\u001b[1;32m     29\u001b[0m     ListIndex,\n\u001b[1;32m     30\u001b[0m     SummaryIndex,\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloading\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     load_graph_from_storage,\n\u001b[1;32m     34\u001b[0m     load_index_from_storage,\n\u001b[1;32m     35\u001b[0m     load_indices_from_storage,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti_modal\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiModalVectorStoreIndex\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstruct_store\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     GPTPandasIndex,\n\u001b[1;32m     40\u001b[0m     PandasIndex,\n\u001b[1;32m     41\u001b[0m )\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/loading.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseIndex\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomposability\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph\u001b[39;00m \u001b[39mimport\u001b[39;00m ComposableGraph\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m INDEX_STRUCT_TYPE_TO_INDEX_CLASS\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstorage_context\u001b[39;00m \u001b[39mimport\u001b[39;00m StorageContext\n\u001b[1;32m      9\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/registry.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlist\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryIndex\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti_modal\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiModalVectorStoreIndex\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m \u001b[39mimport\u001b[39;00m PropertyGraphIndex\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstruct_store\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m PandasIndex\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstruct_store\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SQLStructStoreIndex\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/property_graph/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m PropertyGraphIndex\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretriever\u001b[39;00m \u001b[39mimport\u001b[39;00m PGRetriever\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msub_retrievers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BasePGRetriever\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/property_graph/base.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvector_stores\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msimple\u001b[39;00m \u001b[39mimport\u001b[39;00m DEFAULT_VECTOR_STORE\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseIndex\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransformations\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     SimpleLLMPathExtractor,\n\u001b[1;32m     19\u001b[0m     ImplicitPathExtractor,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mingestion\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     run_transformations,\n\u001b[1;32m     23\u001b[0m     arun_transformations,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_stores\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     LabelledNode,\n\u001b[1;32m     27\u001b[0m     Relation,\n\u001b[1;32m     28\u001b[0m     PropertyGraphStore,\n\u001b[1;32m     29\u001b[0m     TRIPLET_SOURCE_KEY,\n\u001b[1;32m     30\u001b[0m )\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/property_graph/transformations/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransformations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimplicit\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     ImplicitPathExtractor,\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransformations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschema_llm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     SchemaLLMPathExtractor,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransformations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msimple_llm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     SimpleLLMPathExtractor,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperty_graph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransformations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdynamic_llm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     DynamicLLMPathExtractor,\n\u001b[1;32m     12\u001b[0m )\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/property_graph/transformations/schema_llm.py:95\u001b[0m\n\u001b[1;32m     56\u001b[0m DEFAULT_VALIDATION_SCHEMA: List[Triple] \u001b[39m=\u001b[39m [\n\u001b[1;32m     57\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mPRODUCT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUSED_BY\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPRODUCT\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     58\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mPRODUCT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUSED_FOR\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMARKET\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mLOCATION\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPART_OF\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLOCATION\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     84\u001b[0m ]\n\u001b[1;32m     86\u001b[0m DEFAULT_SCHEMA_PATH_EXTRACT_PROMPT \u001b[39m=\u001b[39m PromptTemplate(\n\u001b[1;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mGive the following text, extract the knowledge graph according to the provided schema. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTry to limit to the output \u001b[39m\u001b[39m{max_triplets_per_chunk}\u001b[39;00m\u001b[39m extracted paths.s\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m-------\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSchemaLLMPathExtractor\u001b[39;00m(TransformComponent):\n\u001b[1;32m     96\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    Extract paths from a graph using a schema.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m            The number of workers to use. Defaults to 4.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     llm: LLM\n",
            "File \u001b[0;32m~/Downloads/git_test/RAG/Master-RAG-main/.venv/lib/python3.10/site-packages/llama_index/core/indices/property_graph/transformations/schema_llm.py:141\u001b[0m, in \u001b[0;36mSchemaLLMPathExtractor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m possible_relation_props: Optional[List[\u001b[39mstr\u001b[39m]]\n\u001b[1;32m    135\u001b[0m strict: \u001b[39mbool\u001b[39m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    139\u001b[0m     llm: LLM,\n\u001b[1;32m    140\u001b[0m     extract_prompt: Union[PromptTemplate, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m--> 141\u001b[0m     possible_entities: Optional[TypeAlias] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m     possible_entity_props: Optional[Union[List[\u001b[39mstr\u001b[39m], List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    143\u001b[0m     possible_relations: Optional[TypeAlias] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m     possible_relation_props: Optional[\n\u001b[1;32m    145\u001b[0m         Union[List[\u001b[39mstr\u001b[39m], List[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]]\n\u001b[1;32m    146\u001b[0m     ] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m     strict: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    148\u001b[0m     kg_schema_cls: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    149\u001b[0m     kg_validation_schema: Union[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m], List[Triple]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m     max_triplets_per_chunk: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[1;32m    151\u001b[0m     num_workers: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m,\n\u001b[1;32m    152\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Init params.\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(extract_prompt, \u001b[39mstr\u001b[39m):\n",
            "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/typing.py:311\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
            "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/typing.py:402\u001b[0m, in \u001b[0;36m_SpecialForm.__getitem__\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39m@_tp_cache\u001b[39m\n\u001b[1;32m    401\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, parameters):\n\u001b[0;32m--> 402\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(\u001b[39mself\u001b[39;49m, parameters)\n",
            "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/typing.py:528\u001b[0m, in \u001b[0;36mOptional\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39m@_SpecialForm\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mOptional\u001b[39m(\u001b[39mself\u001b[39m, parameters):\n\u001b[1;32m    524\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optional type.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \n\u001b[1;32m    526\u001b[0m \u001b[39m    Optional[X] is equivalent to Union[X, None].\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     arg \u001b[39m=\u001b[39m _type_check(parameters, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m requires a single type.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m Union[arg, \u001b[39mtype\u001b[39m(\u001b[39mNone\u001b[39;00m)]\n",
            "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/typing.py:171\u001b[0m, in \u001b[0;36m_type_check\u001b[0;34m(arg, msg, is_argument, module, is_class)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, _SpecialForm) \u001b[39mor\u001b[39;00m arg \u001b[39min\u001b[39;00m (Generic, Protocol):\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlain \u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m is not valid as type argument\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (\u001b[39mtype\u001b[39m, TypeVar, ForwardRef, types\u001b[39m.\u001b[39mUnionType, ParamSpec)):\n\u001b[1;32m    173\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
            "\u001b[0;31mTypeError\u001b[0m: Plain typing.TypeAlias is not valid as type argument"
          ]
        }
      ],
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "10b9bfc1-5f2b-4b9e-9934-9844e3b60646",
      "metadata": {
        "id": "10b9bfc1-5f2b-4b9e-9934-9844e3b60646"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_page(title: str):\n",
        "    \"\"\"\n",
        "    Retrieve the full text content of a Wikipedia page.\n",
        "\n",
        "    :param title: str - Title of the Wikipedia page.\n",
        "    :return: str - Full text content of the page as raw string.\n",
        "    \"\"\"\n",
        "    # Wikipedia API endpoint\n",
        "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    # Parameters for the API request\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"titles\": title,\n",
        "        \"prop\": \"extracts\",\n",
        "        \"explaintext\": True,\n",
        "    }\n",
        "\n",
        "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
        "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1 (ben@clavie.eu)\"}\n",
        "\n",
        "    response = requests.get(URL, params=params, headers=headers)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extracting page content\n",
        "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "    return page[\"extract\"] if \"extract\" in page else None\n",
        "\n",
        "full_document = get_wikipedia_page(\"Document_retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a2317cc1-7406-4115-84c2-d0527a4ad22e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "a2317cc1-7406-4115-84c2-d0527a4ad22e",
        "outputId": "643d8793-e8f6-40f7-e380-0bfa4e5fa621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
            "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
            "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
            "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
            "--------------------\n",
            "\n",
            "\n",
            "[Jul 06, 00:07:28] #> Creating directory .ragatouille/colbert/indexes/Doc-1 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:30] [0] \t\t #> Encoding 7 passages..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:35] [0] \t\t avg_doclen_est = 116.42857360839844 \t len(local_sample) = 7\n",
            "[Jul 06, 00:07:35] [0] \t\t Creating 256 partitions.\n",
            "[Jul 06, 00:07:35] [0] \t\t *Estimated* 815 embeddings.\n",
            "[Jul 06, 00:07:35] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/Doc-1/plan.json ..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: number of training points (775) is less than the minimum recommended (2560)\n",
            "used 6 iterations (0.0408s) to cluster 775 items into 256 clusters\n",
            "[0.036, 0.038, 0.038, 0.032, 0.034, 0.034, 0.033, 0.038, 0.029, 0.028, 0.032, 0.03, 0.029, 0.032, 0.036, 0.039, 0.03, 0.026, 0.029, 0.032, 0.029, 0.027, 0.03, 0.038, 0.039, 0.031, 0.031, 0.039, 0.03, 0.041, 0.034, 0.04, 0.03, 0.035, 0.03, 0.03, 0.034, 0.034, 0.027, 0.042, 0.027, 0.044, 0.035, 0.035, 0.034, 0.038, 0.027, 0.03, 0.025, 0.036, 0.028, 0.038, 0.028, 0.026, 0.033, 0.042, 0.04, 0.039, 0.038, 0.04, 0.033, 0.043, 0.029, 0.04, 0.04, 0.044, 0.032, 0.04, 0.033, 0.032, 0.029, 0.024, 0.041, 0.033, 0.041, 0.029, 0.038, 0.031, 0.041, 0.044, 0.037, 0.038, 0.033, 0.037, 0.038, 0.033, 0.039, 0.035, 0.033, 0.029, 0.031, 0.034, 0.032, 0.037, 0.037, 0.032, 0.036, 0.036, 0.032, 0.033, 0.029, 0.035, 0.035, 0.033, 0.036, 0.036, 0.028, 0.025, 0.035, 0.027, 0.042, 0.035, 0.034, 0.038, 0.039, 0.034, 0.031, 0.036, 0.035, 0.032, 0.03, 0.038, 0.026, 0.035, 0.028, 0.035, 0.037, 0.03]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:35] [0] \t\t #> Encoding 7 passages..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.51s/it]\n",
            "1it [00:04,  4.59s/it]\n",
            "100%|██████████| 1/1 [00:00<00:00, 798.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:39] #> Optimizing IVF to store map from centroids to list of pids..\n",
            "[Jul 06, 00:07:39] #> Building the emb2pid mapping..\n",
            "[Jul 06, 00:07:39] len(emb2pid) = 815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 256/256 [00:00<00:00, 15593.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:39] #> Saved optimized IVF to .ragatouille/colbert/indexes/Doc-1/ivf.pid.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done indexing!\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.ragatouille/colbert/indexes/Doc-1'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RAG.index(\n",
        "    collection=[full_document],\n",
        "    index_name=\"Doc-1\",\n",
        "    max_document_length=180,\n",
        "    split_documents=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f929e4fd-2175-465d-bd88-664f67caa576",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f929e4fd-2175-465d-bd88-664f67caa576",
        "outputId": "db0ea720-6be3-4e26-b931-2a7d6a6fe063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading searcher for index Doc-1 for the first time... This may take a few seconds\n",
            "[Jul 06, 00:08:11] #> Loading codec...\n",
            "[Jul 06, 00:08:11] #> Loading IVF...\n",
            "[Jul 06, 00:08:11] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "[Jul 06, 00:08:48] #> Loading doclens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3279.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:08:48] #> Loading codes and residuals...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 130.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:08:48] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:09:20] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "Searcher loaded!\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: . What is an example for form based indexing?, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 2019, 2742, 2005, 2433, 2241, 5950, 2075, 1029,\n",
            "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
            "         103,  103,  103,  103,  103,  103,  103,  103])\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'content': '== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.',\n",
              "  'score': 25.978090286254883,\n",
              "  'rank': 1,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 2},\n",
              " {'content': '== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.',\n",
              "  'score': 19.45407485961914,\n",
              "  'rank': 2,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 4},\n",
              " {'content': '=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.',\n",
              "  'score': 19.071989059448242,\n",
              "  'rank': 3,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 3}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = RAG.search(query=\"What is an example for form based indexing?\", k=3)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ca1cbbc7-bd6e-488d-9419-740a62eb097a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca1cbbc7-bd6e-488d-9419-740a62eb097a",
        "outputId": "97fb2c8b-e3fb-49c8-ff8b-f0ed8ae43f94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.'),\n",
              " Document(page_content='== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.'),\n",
              " Document(page_content='=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = RAG.as_langchain_retriever(k=3)\n",
        "retriever.invoke(\"What is an example for form based indexing?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zn5ZK6ycXxqX",
      "metadata": {
        "id": "zn5ZK6ycXxqX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "033667bb55444c3f9f629dd9ede1ec99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088c9c3f25f7404cb36c641a85026683": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51cad1a6c9134a1c9b818222ac7138e7",
            "placeholder": "​",
            "style": "IPY_MODEL_61af1a241ae54cf5ab71425047c34d3d",
            "value": "tokenizer.json: 100%"
          }
        },
        "0b1d585d85824f888d39522ecb8a6f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba71b0eaff04537bc50bbca33aa4630",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac87a6e34984140a02a704c3e4ccf48",
            "value": "artifact.metadata: 100%"
          }
        },
        "119d9d2a3ae64961a46254e7a0a96e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "139fc4cf87d6413b852799dd74e9bab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16840916a2f45f1a11511542aff5b90",
            "placeholder": "​",
            "style": "IPY_MODEL_b5f3df4f63c84fcf9222e95d5380a899",
            "value": " 112/112 [00:00&lt;00:00, 2.63kB/s]"
          }
        },
        "1a13075d97244a8dad0d45bf48378d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_088c9c3f25f7404cb36c641a85026683",
              "IPY_MODEL_c793d1c900904cca8ffedf8aff00d9bc",
              "IPY_MODEL_8623a516b70244efb6d672cd81b142a8"
            ],
            "layout": "IPY_MODEL_37314ac1be75491fbcb9b1545dc3badc"
          }
        },
        "1b26567be0e547bf9653330ee3e9657a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1157f83feb4b6cad7ef629a67f8e47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9de6e09f82454381a7becdec58e8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d54451d0174a8bb63aceef38882400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_841c4cb47e564e0ebb8095778d66c009",
            "max": 438349816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_252fa7545c1743f39d91cac5f3bfd98f",
            "value": 438349816
          }
        },
        "22cf57b760304a978df66d62eed18444": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce12ae54e3424ac8835ab37b5d2538a4",
              "IPY_MODEL_6c9de4615d71479ba94ee6c71de73ccb",
              "IPY_MODEL_232ef42c0b9242a993254f861575d96f"
            ],
            "layout": "IPY_MODEL_4606c9d425314c089779736ccd5e2450"
          }
        },
        "232ef42c0b9242a993254f861575d96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd7c87d28b149cb940316e1349fee7e",
            "placeholder": "​",
            "style": "IPY_MODEL_3978e89d4c3e4d79b2878d24cb9b9c04",
            "value": " 743/743 [00:00&lt;00:00, 31.2kB/s]"
          }
        },
        "252fa7545c1743f39d91cac5f3bfd98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c02a1c5ce2e44efbe2052dcc585b8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37314ac1be75491fbcb9b1545dc3badc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3978e89d4c3e4d79b2878d24cb9b9c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d3699228def403bbee1a5831c0ef5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf0334b4758450892167661416980ab",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6468201ba1814586a23be3ed3f78f190",
            "value": 112
          }
        },
        "4606c9d425314c089779736ccd5e2450": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b90df0d418488f90c8543486a98e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aec2d6583fb43e28748dac7ab2baab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f864969ec82b4317ba1e703c1c8d22c1",
            "placeholder": "​",
            "style": "IPY_MODEL_c33ad59265ab41aba4c0e1cd7ee3070c",
            "value": " 438M/438M [00:03&lt;00:00, 142MB/s]"
          }
        },
        "4ba71b0eaff04537bc50bbca33aa4630": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be9692e8be043c489f06a3abf27c64d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f08bd4dab974813aa757ec9c4aa963a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cad1a6c9134a1c9b818222ac7138e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5498b24697224a8eb9a4ecfde6ac4846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59123ebb89ad4cbdb1e720883ecda233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6a1048895c4491ad1e68ae54e8f8e9",
            "placeholder": "​",
            "style": "IPY_MODEL_5498b24697224a8eb9a4ecfde6ac4846",
            "value": "model.safetensors: 100%"
          }
        },
        "5c3f767339684ba894d39282b9edbbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e9de6e09f82454381a7becdec58e8bf",
            "max": 1633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f347b06929df4fab84b1ab26338f4af6",
            "value": 1633
          }
        },
        "5dd7c87d28b149cb940316e1349fee7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605810870a4040deb1cd10ab0a057d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61af1a241ae54cf5ab71425047c34d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6468201ba1814586a23be3ed3f78f190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b363d6326ea427389d849068c012232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c255f2548db49dcae4895a12932ce00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9844837561f6449485a618a5ddefabdc",
              "IPY_MODEL_8661582dd02949ab9d922551b764c7b9",
              "IPY_MODEL_ac4a22ba42da4369acd7a615f7e0b863"
            ],
            "layout": "IPY_MODEL_d22750241cf04e32a11e7bc3a68cc2f4"
          }
        },
        "6c9de4615d71479ba94ee6c71de73ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b363d6326ea427389d849068c012232",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d690a1ba354771bb838a2b0b18b79e",
            "value": 743
          }
        },
        "779f2ee7130e4d44b213dab4098672e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "796ec3b798154839bfba5d5f26ba0eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac87a6e34984140a02a704c3e4ccf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8371a09564324bf5ade74da741e1afc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "841c4cb47e564e0ebb8095778d66c009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8623a516b70244efb6d672cd81b142a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8dcb6be89934c408501870533049506",
            "placeholder": "​",
            "style": "IPY_MODEL_605810870a4040deb1cd10ab0a057d5a",
            "value": " 466k/466k [00:00&lt;00:00, 5.60MB/s]"
          }
        },
        "8661582dd02949ab9d922551b764c7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1157f83feb4b6cad7ef629a67f8e47",
            "max": 405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e56ab04c7b54dba911e615c64c8e8c8",
            "value": 405
          }
        },
        "8bc753efac9445ddad71fca8a8ed3ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d73beaf48cf49d39b0e0282883443a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f75d8d2a1ab4abc8b96fadf5f600dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59123ebb89ad4cbdb1e720883ecda233",
              "IPY_MODEL_20d54451d0174a8bb63aceef38882400",
              "IPY_MODEL_4aec2d6583fb43e28748dac7ab2baab0"
            ],
            "layout": "IPY_MODEL_ed62cedbc6024c61b76131f992e31af2"
          }
        },
        "91d690a1ba354771bb838a2b0b18b79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9844837561f6449485a618a5ddefabdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b26567be0e547bf9653330ee3e9657a",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd945ef26ff46a481966617b067213b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9dd945ef26ff46a481966617b067213b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e56ab04c7b54dba911e615c64c8e8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6116981916849eebf946d98ae8691e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a711db6e16974e498d689038a66344de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da31decacd0a49fd8804be39dfab86f3",
              "IPY_MODEL_3d3699228def403bbee1a5831c0ef5ca",
              "IPY_MODEL_139fc4cf87d6413b852799dd74e9bab4"
            ],
            "layout": "IPY_MODEL_46b90df0d418488f90c8543486a98e9e"
          }
        },
        "a7e8f141bc434de6826b9d288710ae71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a924f492ca3f4a5fbd48c57aee80c767": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4a22ba42da4369acd7a615f7e0b863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc753efac9445ddad71fca8a8ed3ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_8371a09564324bf5ade74da741e1afc6",
            "value": " 405/405 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "ac6a1048895c4491ad1e68ae54e8f8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e438a896a44bc58a805ccc5ab03dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5f3df4f63c84fcf9222e95d5380a899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b75a53aa019d4fb3a1dd49fae3b71028": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9463b08a33e4bdeaa2f13f307c94a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5f73bc04a04df1bec10ec485127439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75a53aa019d4fb3a1dd49fae3b71028",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e438a896a44bc58a805ccc5ab03dc4",
            "value": 231508
          }
        },
        "c16840916a2f45f1a11511542aff5b90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33ad59265ab41aba4c0e1cd7ee3070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c793d1c900904cca8ffedf8aff00d9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a924f492ca3f4a5fbd48c57aee80c767",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_119d9d2a3ae64961a46254e7a0a96e82",
            "value": 466081
          }
        },
        "c8dcb6be89934c408501870533049506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcadf9a603b48acb63dae5b8ae018e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc321c998b874fb79b1aedcdbf8eb532": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1cace3748c49999acec51380c87808",
              "IPY_MODEL_ba5f73bc04a04df1bec10ec485127439",
              "IPY_MODEL_faaa3db108f54b2b8cc68d26f814cb87"
            ],
            "layout": "IPY_MODEL_4f08bd4dab974813aa757ec9c4aa963a"
          }
        },
        "ccf0334b4758450892167661416980ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce12ae54e3424ac8835ab37b5d2538a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6116981916849eebf946d98ae8691e0",
            "placeholder": "​",
            "style": "IPY_MODEL_779f2ee7130e4d44b213dab4098672e2",
            "value": "config.json: 100%"
          }
        },
        "d1773c06eeee4678953761276e51dcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d22750241cf04e32a11e7bc3a68cc2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da31decacd0a49fd8804be39dfab86f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_796ec3b798154839bfba5d5f26ba0eb2",
            "placeholder": "​",
            "style": "IPY_MODEL_2c02a1c5ce2e44efbe2052dcc585b8ab",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ed62cedbc6024c61b76131f992e31af2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1cace3748c49999acec51380c87808": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e8f141bc434de6826b9d288710ae71",
            "placeholder": "​",
            "style": "IPY_MODEL_cbcadf9a603b48acb63dae5b8ae018e3",
            "value": "vocab.txt: 100%"
          }
        },
        "f347b06929df4fab84b1ab26338f4af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f55f34da36fb4016a4a0494086c64641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b1d585d85824f888d39522ecb8a6f1f",
              "IPY_MODEL_5c3f767339684ba894d39282b9edbbb7",
              "IPY_MODEL_fad322935e6b4fbc8276abc2b85e1836"
            ],
            "layout": "IPY_MODEL_4be9692e8be043c489f06a3abf27c64d"
          }
        },
        "f864969ec82b4317ba1e703c1c8d22c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faaa3db108f54b2b8cc68d26f814cb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9463b08a33e4bdeaa2f13f307c94a4e",
            "placeholder": "​",
            "style": "IPY_MODEL_8d73beaf48cf49d39b0e0282883443a3",
            "value": " 232k/232k [00:00&lt;00:00, 2.99MB/s]"
          }
        },
        "fad322935e6b4fbc8276abc2b85e1836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033667bb55444c3f9f629dd9ede1ec99",
            "placeholder": "​",
            "style": "IPY_MODEL_d1773c06eeee4678953761276e51dcf1",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 34.5kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
